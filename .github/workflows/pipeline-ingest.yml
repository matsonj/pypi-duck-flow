name: PyPI Data Pipeline

permissions:
  id-token: write

on:
  workflow_dispatch:
    inputs:
      job_type:
        description: 'Job to run'
        required: true
        default: 'both'
        type: choice
        options:
          - ingest
          - transform
          - both
      start_date:
        description: 'Start Date'
        required: true
        default: ''
      end_date:
        description: 'End Date'
        required: true
        default: ''
  schedule:
    - cron: '0 0 * * *' 
    
jobs:
  setup:
    runs-on: ubuntu-latest
    outputs:
      start_date: ${{ steps.dates.outputs.START_DATE }}
      end_date: ${{ steps.dates.outputs.END_DATE }}
    steps:
      - name: Calculate Dates
        id: dates
        run: |
          if [ -n "${{ github.event.inputs.start_date }}" ] && [ -n "${{ github.event.inputs.end_date }}" ]; then
            echo "START_DATE=${{ github.event.inputs.start_date }}" >> $GITHUB_OUTPUT
            echo "END_DATE=${{ github.event.inputs.end_date }}" >> $GITHUB_OUTPUT
          else
            START_DATE=$(date -d '2 days ago' +%Y-%m-%d)
            END_DATE=$(date -d '1 day ago' +%Y-%m-%d)
            echo "START_DATE=${START_DATE}" >> $GITHUB_OUTPUT
            echo "END_DATE=${END_DATE}" >> $GITHUB_OUTPUT
          fi

  ingest-pypi-data:
    needs: setup
    runs-on: ubuntu-latest
    if: github.event.inputs.job_type == 'ingest' || github.event.inputs.job_type == 'both' || github.event_name == 'schedule'
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
            sparse-checkout: |
              Makefile
            sparse-checkout-cone-mode: false
      
      - id: 'auth'
        name: 'Authenticate to GCP'
        uses: 'google-github-actions/auth@v2'
        with:
          credentials_json: '${{ secrets.GCP_SECRETS }}'

      - name: Pull latest Docker image
        run: docker pull ghcr.io/${{ github.repository }}:latest

      - name: Ingest pypi data
        env:
          START_DATE: ${{ needs.setup.outputs.start_date }}
          END_DATE: ${{ needs.setup.outputs.end_date }}
          PYPI_PROJECT: duckdb
          TABLE_NAME: pypi_file_downloads
          GCP_PROJECT: ${{ secrets.GCP_PROJECT_ID }} 
          TIMESTAMP_COLUMN: timestamp
          DESTINATION: md
          DOCKER_IMAGE: ghcr.io/${{ github.repository }}:latest
          AWS_PROFILE: None
          S3_PATH: None
          motherduck_token: ${{ secrets.MOTHERDUCK_TOKEN }}
          GOOGLE_APPLICATION_CREDENTIALS: ${{ steps.auth.outputs.credentials_file_path }}
        run: |
          make pypi-ingest DOCKER=true

  transform-pypi-data:
    needs: [setup, ingest-pypi-data]
    runs-on: ubuntu-latest
    if: github.event.inputs.job_type == 'transform' || github.event.inputs.job_type == 'both' || github.event_name == 'schedule'
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
            sparse-checkout: |
              Makefile
            sparse-checkout-cone-mode: false
      
      - id: 'auth'
        name: 'Authenticate to GCP'
        uses: 'google-github-actions/auth@v2'
        with:
          credentials_json: '${{ secrets.GCP_SECRETS }}'

      - name: Pull latest Docker image
        run: docker pull ghcr.io/${{ github.repository }}:latest

      - name: Transform pypi data using dbt
        env:
          START_DATE: ${{ needs.setup.outputs.start_date }}
          END_DATE: ${{ needs.setup.outputs.end_date }}
          DBT_TARGET: prod
          DOCKER_IMAGE: ghcr.io/${{ github.repository }}:latest
          motherduck_token: ${{ secrets.MOTHERDUCK_TOKEN }}
          GOOGLE_APPLICATION_CREDENTIALS: ${{ steps.auth.outputs.credentials_file_path }}
        run: |
          make pypi-transform DOCKER=true DBT_TARGET=${DBT_TARGET}
